{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sogang03/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sogang03/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sogang03/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sogang03/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sogang03/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sogang03/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#keras\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers.core import Flatten, Dense, Dropout\n",
    "# from keras.layers import Convolution2D, ZeroPadding2D, MaxPooling2D\n",
    "# from keras.optimizers import SGD\n",
    "from keras.preprocessing import image\n",
    "# from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# from shutil import copyfile\n",
    "\n",
    "# # Copyright 2014-2017 Bert Carremans\n",
    "# # Author: Bert Carremans <bertcarremans.be>\n",
    "# #\n",
    "# # License: BSD 3 clause\n",
    "\n",
    "\n",
    "# def img_train_test_split(img_source_dir, train_size):   \n",
    "#     if not (isinstance(img_source_dir, str)):\n",
    "#         raise AttributeError('img_source_dir must be a string')\n",
    "        \n",
    "#     if not (isinstance(train_size, float)):\n",
    "#         raise AttributeError('train_size must be a float')\n",
    "        \n",
    "#     # Set up empty folder structure if not exists\n",
    "#     if not os.path.exists('data'):\n",
    "#         os.makedirs('data')\n",
    "#     else:\n",
    "#         if not os.path.exists('data/train'):\n",
    "#             os.makedirs('data/train')\n",
    "#         if not os.path.exists('data/validation'):\n",
    "#             os.makedirs('data/validation')\n",
    "    \n",
    "#     # Get the subdirectories in the main image folder\n",
    "    \n",
    "#     subdirs = [subdir for subdir in os.listdir(img_source_dir) if os.path.isdir(os.path.join(img_source_dir, subdir))]\n",
    "    \n",
    "#     for subdir in subdirs:\n",
    "#         subdir_fullpath = os.path.join(img_source_dir, subdir)\n",
    "#         if len(os.listdir(subdir_fullpath)) == 0:\n",
    "#             print(subdir_fullpath + ' is empty')\n",
    "#             break\n",
    "\n",
    "#         train_subdir = os.path.join('data/train', subdir)\n",
    "#         validation_subdir = os.path.join('data/validation', subdir)\n",
    "\n",
    "#         # Create subdirectories in train and validation folders\n",
    "#         if not os.path.exists(train_subdir):\n",
    "#             os.makedirs(train_subdir)\n",
    "\n",
    "#         if not os.path.exists(validation_subdir):\n",
    "#             os.makedirs(validation_subdir)\n",
    "\n",
    "#         train_counter = 0\n",
    "#         validation_counter = 0\n",
    "\n",
    "#         # Randomly assign an image to train or validation folder\n",
    "#         for filename in os.listdir(subdir_fullpath):\n",
    "#             if filename.endswith(\".jpg\") or filename.endswith(\".png\"): \n",
    "#                 fileparts = filename.split('.')\n",
    "\n",
    "#                 if random.uniform(0, 1) <= train_size:\n",
    "#                     copyfile(os.path.join(subdir_fullpath, filename), os.path.join(train_subdir, str(train_counter) + '.' + fileparts[1]))\n",
    "#                     train_counter += 1\n",
    "#                 else:\n",
    "#                     copyfile(os.path.join(subdir_fullpath, filename), os.path.join(validation_subdir, str(validation_counter) + '.' + fileparts[1]))\n",
    "#                     validation_counter += 1\n",
    "                    \n",
    "#         print('Copied ' + str(train_counter) + ' images to data/train/' + subdir)\n",
    "#         print('Copied ' + str(validation_counter) + ' images to data/validation/' + subdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied 91 images to data/train/korean_rice\n",
      "Copied 40 images to data/validation/korean_rice\n",
      "Copied 22 images to data/train/disposable_diaper\n",
      "Copied 13 images to data/validation/disposable_diaper\n",
      "Copied 159 images to data/train/coffee\n",
      "Copied 74 images to data/validation/coffee\n",
      "Copied 45 images to data/train/china_wheat\n",
      "Copied 18 images to data/validation/china_wheat\n",
      "Copied 56 images to data/train/quiver_tree\n",
      "Copied 18 images to data/validation/quiver_tree\n",
      "Copied 209 images to data/train/aluminum_can\n",
      "Copied 79 images to data/validation/aluminum_can\n",
      "Copied 58 images to data/train/styrofoam\n",
      "Copied 27 images to data/validation/styrofoam\n",
      "Copied 4 images to data/train/spruce_budworm\n",
      "Copied 3 images to data/validation/spruce_budworm\n",
      "Copied 4 images to data/train/styrofoam_buoy\n",
      "Copied 1 images to data/validation/styrofoam_buoy\n",
      "Copied 101 images to data/train/newt\n",
      "Copied 41 images to data/validation/newt\n",
      "Copied 80 images to data/train/carpenter_bee\n",
      "Copied 26 images to data/validation/carpenter_bee\n",
      "Copied 52 images to data/train/long_distance_migrant_bird\n",
      "Copied 19 images to data/validation/long_distance_migrant_bird\n",
      "Copied 79 images to data/train/plastic_bag\n",
      "Copied 31 images to data/validation/plastic_bag\n",
      "Copied 31 images to data/train/ink_cartridge\n",
      "Copied 19 images to data/validation/ink_cartridge\n",
      "Copied 196 images to data/train/barley\n",
      "Copied 78 images to data/validation/barley\n",
      "Copied 14 images to data/train/spring_peeper\n",
      "Copied 10 images to data/validation/spring_peeper\n",
      "Copied 194 images to data/train/light_bulb\n",
      "Copied 91 images to data/validation/light_bulb\n",
      "Copied 51 images to data/train/mason_bee\n",
      "Copied 29 images to data/validation/mason_bee\n",
      "Copied 186 images to data/train/tiger\n",
      "Copied 70 images to data/validation/tiger\n",
      "Copied 188 images to data/train/frog\n",
      "Copied 97 images to data/validation/frog\n",
      "Copied 144 images to data/train/adélie_penguin\n",
      "Copied 57 images to data/validation/adélie_penguin\n",
      "Copied 22 images to data/train/electronic_waste\n",
      "Copied 18 images to data/validation/electronic_waste\n",
      "Copied 129 images to data/train/tin_can\n",
      "Copied 71 images to data/validation/tin_can\n",
      "Copied 194 images to data/train/polar_bear\n",
      "Copied 73 images to data/validation/polar_bear\n",
      "Copied 22 images to data/train/ivory_gull\n",
      "Copied 11 images to data/validation/ivory_gull\n",
      "Copied 118 images to data/train/coral\n",
      "Copied 67 images to data/validation/coral\n",
      "Copied 171 images to data/train/plastic_bottle\n",
      "Copied 59 images to data/validation/plastic_bottle\n",
      "Copied 80 images to data/train/gecko\n",
      "Copied 50 images to data/validation/gecko\n",
      "Copied 3 images to data/train/jack_pine_budworm\n",
      "Copied 2 images to data/validation/jack_pine_budworm\n",
      "Copied 134 images to data/train/fishing_line\n",
      "Copied 61 images to data/validation/fishing_line\n",
      "Copied 2 images to data/train/plastic_beverage_holder\n",
      "Copied 1 images to data/validation/plastic_beverage_holder\n",
      "Copied 192 images to data/train/crocodilian\n",
      "Copied 73 images to data/validation/crocodilian\n",
      "Copied 171 images to data/train/lizard\n",
      "Copied 63 images to data/validation/lizard\n",
      "Copied 206 images to data/train/glass_bottle\n",
      "Copied 92 images to data/validation/glass_bottle\n",
      "Copied 110 images to data/train/bumblebee\n",
      "Copied 44 images to data/validation/bumblebee\n",
      "Copied 0 images to data/train/.ipynb_checkpoints\n",
      "Copied 0 images to data/validation/.ipynb_checkpoints\n",
      "Copied 154 images to data/train/banana\n",
      "Copied 75 images to data/validation/banana\n",
      "Copied 37 images to data/train/phytoplankton\n",
      "Copied 11 images to data/validation/phytoplankton\n",
      "Copied 179 images to data/train/snake\n",
      "Copied 88 images to data/validation/snake\n",
      "Copied 106 images to data/train/forest_bird\n",
      "Copied 49 images to data/validation/forest_bird\n",
      "Copied 100 images to data/train/shark\n",
      "Copied 44 images to data/validation/shark\n",
      "Copied 120 images to data/train/lion\n",
      "Copied 58 images to data/validation/lion\n",
      "Copied 144 images to data/train/corn\n",
      "Copied 75 images to data/validation/corn\n",
      "Copied 80 images to data/train/snowy_plover\n",
      "Copied 37 images to data/validation/snowy_plover\n",
      "Copied 143 images to data/train/toad\n",
      "Copied 75 images to data/validation/toad\n",
      "Copied 180 images to data/train/cacao\n",
      "Copied 65 images to data/validation/cacao\n"
     ]
    }
   ],
   "source": [
    "# img_path = \"/home/sogang03/school/128px_image_square_final\"\n",
    "# images = glob.glob(os.path.join(img_path,\"*/*.jpg\" ))\n",
    "\n",
    "\n",
    "# img_train_test_split(img_path, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/sogang03/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sogang03/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sogang03/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sogang03/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sogang03/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sogang03/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4761 images belonging to 46 classes.\n",
      "Found 2103 images belonging to 46 classes.\n"
     ]
    }
   ],
   "source": [
    "#preprocess image \n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_data_dir = './data/train'\n",
    "validation_data_dir = './data/validation'\n",
    "\n",
    "data_dir = './\"/home/sogang03/school/128px_image_square_final\"'\n",
    "\n",
    "trdata = ImageDataGenerator()\n",
    "traindata = trdata.flow_from_directory(directory= train_data_dir,class_mode='input', target_size=(224,224), batch_size=32)\n",
    "vldata = ImageDataGenerator()\n",
    "valdata = vldata.flow_from_directory(directory= validation_data_dir,class_mode='input', target_size=(224,224), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traindata 149\n",
      "valdata 66\n"
     ]
    }
   ],
   "source": [
    "print(\"traindata\", len(traindata))\n",
    "print(\"valdata\", len(valdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sogang03/miniconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/sogang03/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "=================================================================\n",
      "Total params: 134,260,544\n",
      "Trainable params: 134,260,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model summary\n",
    "#https://machinelearningmastery.com/how-to-use-transfer-learning-when-developing-convolutional-neural-network-models/\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "model = VGG16(weights=None, input_shape=(224,224,3), pooling=None)\n",
    "model.layers.pop()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training setting\n",
    "from keras import optimizers\n",
    "\n",
    "opt = optimizers.SGD(learning_rate=0.001)\n",
    "model.compile(optimizer=opt, loss =\"categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sogang03/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "(4761, 4096)\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import Model\n",
    "\n",
    "model = Model(inputs=model.inputs, outputs=model.layers[-1].output)\n",
    "# get extracted features\n",
    "features = model.predict(traindata)\n",
    "print(features.shape)\n",
    "\n",
    "# hist = model.fit_generator(generator= traindata, steps_per_epoch=len(traindata),\n",
    "#                            validation_data= valdata, validation_steps=len(valdata),\n",
    "#                            epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump\n",
    "\n",
    "# save to file\n",
    "dump(features, open('dog.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 4761 samples in 2.767s...\n",
      "[t-SNE] Computed neighbors for 4761 samples in 140.681s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 4761\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 4761\n",
      "[t-SNE] Computed conditional probabilities for sample 3000 / 4761\n",
      "[t-SNE] Computed conditional probabilities for sample 4000 / 4761\n",
      "[t-SNE] Computed conditional probabilities for sample 4761 / 4761\n",
      "[t-SNE] Mean sigma: 1.106733\n",
      "[t-SNE] Computed conditional probabilities in 0.201s\n",
      "[t-SNE] Iteration 50: error = 84.3228607, gradient norm = 0.0360653 (50 iterations in 7.909s)\n",
      "[t-SNE] Iteration 100: error = 79.8559113, gradient norm = 0.0075125 (50 iterations in 3.316s)\n",
      "[t-SNE] Iteration 150: error = 79.8361893, gradient norm = 0.0069412 (50 iterations in 2.068s)\n",
      "[t-SNE] Iteration 200: error = 79.8341446, gradient norm = 0.0078816 (50 iterations in 1.935s)\n",
      "[t-SNE] Iteration 250: error = 79.8335266, gradient norm = 0.0064509 (50 iterations in 1.939s)\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 79.833527\n",
      "[t-SNE] Iteration 300: error = 2.3176842, gradient norm = 0.0010404 (50 iterations in 3.750s)\n",
      "[t-SNE] Iteration 350: error = 2.1464496, gradient norm = 0.0002806 (50 iterations in 5.577s)\n",
      "[t-SNE] Iteration 400: error = 2.0520592, gradient norm = 0.0001299 (50 iterations in 5.562s)\n",
      "[t-SNE] Iteration 450: error = 1.9927897, gradient norm = 0.0000779 (50 iterations in 5.729s)\n",
      "[t-SNE] Iteration 500: error = 1.9530793, gradient norm = 0.0000560 (50 iterations in 5.767s)\n",
      "[t-SNE] Iteration 550: error = 1.9252992, gradient norm = 0.0000432 (50 iterations in 5.949s)\n",
      "[t-SNE] Iteration 600: error = 1.9060938, gradient norm = 0.0000354 (50 iterations in 5.839s)\n",
      "[t-SNE] Iteration 650: error = 1.8927333, gradient norm = 0.0000311 (50 iterations in 5.805s)\n",
      "[t-SNE] Iteration 700: error = 1.8826005, gradient norm = 0.0000270 (50 iterations in 5.836s)\n",
      "[t-SNE] Iteration 750: error = 1.8745410, gradient norm = 0.0000237 (50 iterations in 5.843s)\n",
      "[t-SNE] Iteration 800: error = 1.8682628, gradient norm = 0.0000215 (50 iterations in 6.091s)\n",
      "[t-SNE] Iteration 850: error = 1.8632267, gradient norm = 0.0000219 (50 iterations in 6.585s)\n",
      "[t-SNE] Iteration 900: error = 1.8587692, gradient norm = 0.0000188 (50 iterations in 8.717s)\n",
      "[t-SNE] Iteration 950: error = 1.8550566, gradient norm = 0.0000191 (50 iterations in 8.157s)\n",
      "[t-SNE] Iteration 1000: error = 1.8523706, gradient norm = 0.0000183 (50 iterations in 8.039s)\n",
      "[t-SNE] KL divergence after 1000 iterations: 1.852371\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('dog.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "tsne = TSNE(n_components=3, perplexity=30, verbose =2).fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history display\n",
    "\n",
    "plt.plot(hist.history[\"acc\"])\n",
    "plt.plot(hist.history['val_acc'])\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tsne\n",
    "tsne = TSNE(n_components=3, perplexity=30, verbose=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
